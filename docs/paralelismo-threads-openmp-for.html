<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<meta name="author" content="Marcos Irigoyen">
<title>Programação Paralela</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/styles/github.min.css">
<style>.toc-current{font-weight: bold;} .toc-root{font-family: "Open Sans","DejaVu Sans",sans-serif;
                       font-size: 0.9em;} #content{display: flex; flex-direction: column; flex: 1 1 auto;}
             .nav-footer{text-align: center; margin-top: auto;}
             .nav-footer > p > a {white-space: nowrap;}</style>
</head>
<body id="paralelismo-threads-openmp-for" class="book toc2 toc-left text-justify">
<div id="header" style="max-width: 80%;">
<h1>Programação Paralela</h1>
<div class="details">
<span id="author" class="author">Marcos Irigoyen</span><br>
<span id="email" class="email"><a href="mailto:mvbirigoyen@gmail.com">mvbirigoyen@gmail.com</a></span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Sumário</div>
<p><span class="toc-root"><a href="index.html">Programação Paralela</a></span></p><ul class="sectlevel1">
<li><a href="gargalo-de-von-neumann.html">Gargalo de Von Neumann e a Cache</a>
</li>
<li><a href="pipelining-e-vetorizacao.html">Pipelining e Vetorização</a>
</li>
<li><a href="fontes-de-demanda-por-performance-precisao.html">Fontes de demanda por performance: precisão</a>
</li>
<li><a href="multithreading-e-threads-de-hardware.html">Threading por hardware e hyperthreading</a>
</li>
<li><a href="paralelismo-threads-openmp-for.html"><span class="toc-current">Paralelismo por Threads com OpenMP</span></a>
<ul class="sectlevel2">
<li><a href="paralelismo-threads-openmp-for.html#_introdução_5">Introdução</a>
</li>
<li><a href="paralelismo-threads-openmp-for.html#_o_algoritmo_base_o_crivo_de_erastóstenes">O algoritmo base: o Crivo de Erastóstenes</a>
</li>
<li><a href="paralelismo-threads-openmp-for.html#_relacionados_5">Relacionados</a>
</li>
<li><a href="paralelismo-threads-openmp-for.html#_íntegra_dos_códigos_5">Íntegra dos códigos</a>
</li>
</ul>
</li>
<li><a href="paralelismo-threads-openmp-escopos-critical.html">Paralelismo por Threads com OpenMP: Escopo e seções críticas</a>
</li>
</ul>
</div>
</div>
<div id="content" style="max-width: 80%;">
<div class="sect1">
<h2 id="paralelismo-threads-openmp-for">Paralelismo por Threads com OpenMP</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_introdução_5">Introdução</h3>
<div class="paragraph">
<p>Enfim, programação paralela! Retornando um pouco ao papo histórico, as forças motrizes do avanço em sistemas
computacionais foram, por muito tempo, aplicações militares e/ou científicas. Computadores eram muito mais custosos,
maiores, e acoplados que os atuais: a montagem dos computadores e suas peças eram inteiramente das empresas de
computadores da época, como a IBM e a Remmington Rand, que serviam como fabricantes e integradores dos sistemas (e
locatárias). Boa parte das inovações em arquitetura de computadores partiam dessas "corridas" pelos contratos de
licitação, como o contrato para o LARC do LLNL (Lawrence Livermore National Laboratory), que gerou o UNIVAC LARC em 1960
e influenciou o IBM 7030 de 1961. No LARC, já tínhamos acesso à forma geral de comunicação que usamos com OpenMP —
memória compartilhada.</p>
</div>
<div class="paragraph">
<p>Para abarcar as diferentes formas que um ou mais computadores (e hoje em dia, também adequando-se a programas) operam,
Michael J. Flynn elaborou uma taxonomia baseada no fluxo de dados e instruções ao sistema, de onde surgem as definições
de SISD ("Single Instruction, Single Data", como os sequenciais), SIMD (MD &#8594; "Multiple Data", como com vetorização),
MISD (muitíssimo pouco abordado desde a época, SISD acaba ofuscando), e MIMD (mais genérico de todos, ideal para
sistemas distribuídos). Naturalmente, para processamentos SIMD e MIMD era necessária a distribuição dos dados às
componentes computacionais, e tanto a limitação pelo custo de memória em si quando pela latência em acesso e transmissão
de dados entre memórias separadas fizeram dos sistemas de memória compartilhada a primeira alternativa.
Alternativamente, a comunicação por troca de mensagens surge bem mais tarde, após avanços significativos na redução da
latência.</p>
</div>
<div class="paragraph">
<p>Inicialmente, OpenMP surgiu como uma API para programação paralela de memória compartilhada independente de sistema
operacional e plataforma de hardware, focado em cargas de trabalho particionáveis em cargas paralelas independentes
entre si, simplificando boa parte do processo de paralelização à inclusão de diretivas ao compilador. Se você viu os
gráficos obtidos na postagem anterior, teve um vislumbre do potencial de redução do tempo de execução em um programa
paralelo com OpenMP. Aqui, vamos abordar o uso do diretiva <code>omp parallel for</code> para paralelização de loops com um exemplo
no cálculo da quantia de números primos de 2 (ou 1, ou 0) a um N arbitrário, sobretudo abordando os primeiros pitfalls
que se podem encontrar na paralelização de um algoritmo. A partir daqui, tudo tem um pouco de seção de experimentos.</p>
</div>
</div>
<div class="sect2">
<h3 id="_o_algoritmo_base_o_crivo_de_erastóstenes">O algoritmo base: o Crivo de Erastóstenes</h3>
<div class="paragraph">
<p>Existem múltiplos algoritmos para o cálculo de números primos, e apesar do Crivo não ser um dos primeiros a se pensar,
é um algoritmo simples: você lista todos os números entre 2 e o N alvo e itera por cada número — se o número não estiver
marcado, ele é um número primo: você adiciona ao total de números primos e marca cada múltiplo desse número que esteja
contido na lista; se o número estiver marcado, ele é múltiplo de um número primo e pode ser ignorado. Em contraste ao
primeiro algoritmo que se pode pensar (para cada número, verificar se ele é divisível por algum dos números anteriores
a ele), o cálculo reduz a quantia de comparações feitas às custas de um maior uso de memória. Com algumas otimizações,
como redução do espaço de busca aos números ímpares (porque todo número par ou é 2 ou é múltiplo dele) e marcação a
partir do quadrado do número (múltiplos menores já seriam marcados por primos menores), temos o código serial:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">//for further details, check the source on the repository.
inline void mark_multiples(unsigned long base_index, unsigned long N, bool* odd_integer_field){

    unsigned long start = i_val_square_index(base_index); //base_index + square offset
    unsigned long incr = i_odd_multiples_incr(base_index);
    unsigned long limit = (N-3)/2;
    for (unsigned long i = start; i &lt;= limit; i+= incr){
        odd_integer_field[i] = true;
    }
}

return_data count_primes_serial(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    for (unsigned long i = 0; i &lt;= N_in_odd_index; i++){
        if (!odd_integer_field[i]){
            mark_multiples(i, N, odd_integer_field);
            prime_count++;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Imaginemos que eu emocionado com o desempenho visto no relatório anterior, coloco cegamente a diretiva de <code>parallel for</code>
na função <code>count_primes_serial</code>, sem considerar nem o funcionamento do algoritmo e nem o funcionamento do próprio
OpenMP, resultando na função:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">return_data count_primes_naive_parallel(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    #pragma omp parallel for num_threads(num_threads)
    for (unsigned long i = 0; i &lt;= N_in_odd_index; i++){
        if (!odd_integer_field[i]){
            mark_multiples(i, N, odd_integer_field);
            prime_count++;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>E, para montar um gráfico bonito, começo a coletar os dados da execução: tempo e número de primos para cada combinação
de número de threads, N arbitrário e modo de execução que eu decidir. Ao coletar os dados, muito provavelmente
encontrarei como a seguinte tabela (feita apartir de dados coletados na execução desses códigos):</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
<col style="width: 5%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">NUM_THREADS</p></td>
<td class="tableblock halign-left valign-top" colspan="3"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top" colspan="3"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top" colspan="3"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top" colspan="3"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top" colspan="3"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top" colspan="3"><p class="tableblock">6</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" colspan="2"></td>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">PRIME_COUNT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TIME_MS</p></td>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">PRIME_COUNT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TIME_MS</p></td>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">PRIME_COUNT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TIME_MS</p></td>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">PRIME_COUNT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TIME_MS</p></td>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">PRIME_COUNT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TIME_MS</p></td>
<td class="tableblock halign-left valign-top" colspan="2"><p class="tableblock">PRIME_COUNT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">TIME_MS</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" colspan="2"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">var</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mean</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MODE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">MAX_NUMBER</p></td>
<td class="tableblock halign-left valign-top" colspan="18"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NAIVE_PARALLEL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0021044</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0632372</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.101628</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.144956</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.188163</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.383981</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NAIVE_PARALLEL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">50</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">15</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0017794</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">15</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.053502</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">12.6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">18.8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0900938</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11.6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.135943</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">9.6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6.3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.183339</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">13.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">3.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.239459</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SERIAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">9.56e-05</p></td>
<td class="tableblock halign-left valign-top" colspan="15"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SERIAL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">50</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">15</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0001964</p></td>
<td class="tableblock halign-left valign-top" colspan="15"></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Podemos ver pela média não-natural e variância não-nula na contagem de primos de que os resultados da versão paralela
variam entre as amostras, o que não faz sentido para um algoritmo determinístico como este. Para piorar, além de
incorreto, o programa também está mais lento, perdendo significativamente a comparação por tempo em todos os casos.
Estes resultados são consequências da negligência a análise do algoritmo em si e do custo adicional introduzido pelo
OpenMP para uso das threads.</p>
</div>
<div class="sect3">
<h4 id="_analisando_e_corrigindo_os_problemas">Analisando e corrigindo os problemas</h4>
<div class="paragraph">
<p>O primeiro problema se dá por dois fatores: o acesso simultâneo da variável prime_count e a dependência entre iterações
dos resultados de iterações anteriores. Para o primeiro fator, é possível que múltiplas threads tentem alterar o
prime_count ao mesmo tempo, de forma que as alterações feitas por uma thread não cheguem a tempo de serem incorporadas
nas demais, que efetivamente ignorariam-na. Para solucionar isso, podemos usar diretivas atômicas (para uso de
instruções atômicas, i.e. que não podem ser interrompidas no meio), seções críticas (que só podem ser acessadas por uma
única thread por vez), ou variáveis privadas. Para solucionar isso, dou a cada thread uma versão privada de prime_count
e, no fim da execução paralela, somo todos os prime_count privados em uma só prime_count — tudo através da claúsula
reduce. O segundo fator é menos trivial, é uma quebra do princípio de independência entre as partições da carga de
trabalho, e pode não ter solução para um dado algoritmo. No caso do crivo de Erastóstenes, a checagem de um número
múltiplo de um primo poderia ocorrer antes da marcação desse número após a checagem do número primo ao qual ele é
múltiplo. Felizmente, podemos extrair subconjuntos da carga que são particionáveis: dado a contagem de todos os números
primos entre 2 e I e a marcação de seus múltiplos, temos que todos os números de 2 até \(I^2\) são ou números
primos ou múltiplos de primos já descobertos (e portanto marcados). Com isso, começamos paralelizando o crivo para o
subconjunto de números entre 3 e 9, e então extendemos para 9 e 81, e então 81 e 6561, e por aí vai.</p>
</div>
<div class="paragraph">
<p>O segundo problema é uma bronca, podendo existir ou deixar de existir em diferentes sistemas computacionais e tamanhos
de carga, sendo frequentemente causado por fatores desconsiderados durante a elaboração dos algoritmos. O tempo de
execução (o tempo real, em que vivemos, não o de CPU) de um algoritmo é, inevitavelmente, função da implementação do
algoritmo e do sistema que o executa. Evidências dessa afirmação foram vistas nos relatórios anteriores, desde o impacto
da cache no tempo de execução até a ineficácia do multithreading para cargas pequenas demais. Pelo funcionamento da
função e os N arbitrários escolhidos no experimento, é difícil supor uma causa ao aumento de tempo além do pequeníssimo
N arbitrário: o algoritmo aparenta, na maior parte do tempo, estar lendo e escrevendo num vetor de booleanos,
caracterizando-o como limitado por memória, enquanto que o pequeno valor de N sugere a possibilidade de guardar todo o
vetor de booleanos na cache L1 (exclusiva de cada core). Ao se paralelizar este código em memória compartilhada, as
mudanças feitas por outra thread no vetor invalidariam a cache L1 de threads em outros cores, aumentando a latência de
acesso a memória (basicamente como no false sharing). Para isso, não há muito a se fazer além de aumentar o tamanho do
problema — como há dependência entre valores de alguns primos anteriores, seria necessário sincronizar os vetores
booleanos caso se usasse vetores booleanos privados. Outro problema de performance que podemos corrigir, entretanto, vem
pelo insight da natureza da carga de trabalho: o tamanho da carga para processamento de um número não é igual para todos
os números. Podemos ver isso, primeiramente, entre números primos e não primos, onde a marcação de múltiplos dos primos
leva um tempo proporcional à razão entre o N arbitrário e o número primo, enquanto que o trabalho para um não-primo é
somente a checagem da marcação. Isso nos leva a dois problemas: a distância entre um número primo e o número primo
seguinte aumenta conforme a magnitude do número, fazendo com que a divisão da carga em subintervalos regulares de
\()2,N(\) resulte em cargas desequilibradas. Nomeadamente, podemos classificar estas fontes de perda de
desempenho (ou overhead) por comunicação e por desequilíbrio de carga. Para este segundo problema, mais solucionável,
basta definirmos como dividir a carga no OpenMP: o <code>parallel for</code> aceita uma claúsula <code>schedule</code> para definição de como
a carga é dividida entre as threads, assumindo por padrão uma divisão estática (definida em tempo de compilação) em
blocos de tamanho \(\frac{T,P}\), com T sendo o número de iterações do laço for e P o total de threads da seção.
Daqui, seja por alguma metaheurística, thumb rule, ou testagem, você arbitra por uma modalidade de agendamento (entre
<code>static</code>, <code>dynamic</code> e <code>guided</code>, enquanto <code>auto</code> e <code>runtime</code> servem pra passar essa escolha pra outra etapa) e um tamanho
de bloco.</p>
</div>
<div class="paragraph">
<p>Para solucionar estes problemas, duas alternativas foram feitas: uma paralelizando os subconjuntos particionáveis
através de tasks, que serão abordadas em uma próxima postagem, e uma paralelizando o for do subconjunto. As duas versões
estão dispostas abaixo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">return_data count_primes_task(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    task_queue pending_values = {(unsigned long) (N/std::log(N))};
    unsigned long N_in_odd_index = (N-3)/2;
    unsigned long prio = omp_get_max_task_priority();
    auto start = utils::mark_time();

    #pragma omp parallel num_threads(num_threads)
    {
        #pragma omp single
        {
            unsigned long i = 0;
            unsigned long last_index = 1; //just putting a different value
            unsigned long progress_threshold = i_val_square_index(i)-1;
            while (i &lt;= N_in_odd_index){
                if (i != last_index){
                    if (!odd_integer_field[i]){
                        task_info* pending_task = pending_values.push({i, false});
                        #pragma omp task firstprivate(pending_task) priority(prio)
                        {
                            mark_multiples(pending_task-&gt;value, N, odd_integer_field);
                            pending_task-&gt;done = true;
                        }
                        prio = (prio-1)==0 ? 1 : prio-1;
                        prime_count++;
                    }
                }
                last_index = i;

                if (!pending_values.empty()){
                    if (pending_values.front-&gt;done){
                        progress_threshold = i_val_square_index(pending_values.pop().value)-1;
                    }
                }
                i = i+1 &lt; progress_threshold ? i+1 : progress_threshold;
            }
        }
    }
    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}

return_data count_primes_for_dynamic(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    #pragma omp parallel num_threads(num_threads) reduction(+:prime_count)
    {
        prime_count = 0;
        for (unsigned long i = 0; i &lt;= N_in_odd_index;){
            unsigned long progress_threshold = i_val_square_index(i)-1;
            progress_threshold = progress_threshold &gt; N_in_odd_index ? N_in_odd_index : progress_threshold;
            unsigned long partition_size = (progress_threshold-i)/(12*num_threads);
            partition_size = partition_size == 0 ? 1 : partition_size;
            #pragma omp for schedule(dynamic,partition_size)
            for (unsigned long j = i; j &lt;= progress_threshold; j++){
                if (!odd_integer_field[j]){
                    mark_multiples(j, N, odd_integer_field);
                    prime_count++;
                }
            }
            i = progress_threshold + 1;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_comparando_as_soluções">Comparando as soluções</h4>
<div class="paragraph">
<p>Idealmente, a paralelização por tasks evitaria a sincronização necessária para cada for dos subconjuntos, bem como
permitiria a expansão da carga de trabalho enquanto outras tarefas ainda estão sendo concluídas (além de não ter que
passar tarefas simples demais, como números já marcados, às demais threads). A paralelização por
for, por sua vez, seria mais simples e evitaria a comunicação do término de tasks feito através da fila <code>pending_values</code>
da implementação por tasks. "Qual seria mais rápida?" é uma questão que, pela simples análise do código, não pode ser
definida com exatidão: seria necessário considerar fatores externos demais à lógica dos programas para ter uma boa
confiança ou justificativa do resultado. Teríamos, no melhor, modelado o tempo de execução em função das operações
realizadas em cada implementação e variáveis relacionadas ao custo dessas operações na máquina, que, a menos que sejam
todas operações da mesma natureza, vão depender da máquina em si. Fazendo, então, a comparação no meu computador:</p>
</div>
<script src="https://cdn.plot.ly/plotly-3.0.1.min.js" charset="utf-8"></script>
<div id="plot_wrapper" style="display:flex; flex-direction:column">
    <div id="plot_times" style="margin:auto;width:85%;aspect-ratio: 16 / 9">Se você está vendo isso aqui, o script do plot deu pau</div>
    <div style="margin:auto; width:45%; display:flex; align-items:center">
        <input type="range" min="2" max ="12" value="2" id="select_plot_data" name="Número de threads" style="flex: 1"/>
        <label id="num_threads" style="margin-left: 8px"></label>
    </div>
</div>
<script>
    cache = {}
    async function fetch_data(path){
        var data = []
        if (cache[path]){data = cache[path]; console.log("omggg acertei o cache mais preguiçoso que existe")}
        else{
            const response = await fetch(path)
            data = await response.json()
            cache[path] = data
        }
        processData(data, {flag: path.split('/')[1].split('_').at(0)})
    }

    function processData(json_data, extra){

        series = structuredClone(json_data)

        const dash_types = ["solid", "dashdot"]
        var counter = 0
        for (const [key, val] of Object.entries(series)){
            series[key]["mode"] = "lines"
            series[key]["type"] = "scatter"
            series[key]["name"] = key
            series[key]["line"] = {dash:dash_types[counter]}
            counter = (counter+1)
        }
        document.getElementById("plot_times").innerText = ""
        var traces = Object.values(series)
        Plotly.newPlot("plot_times", traces,
            {
                title: {text: `Timings for ${extra.flag} threads`, subtitle: {text: `5 samples per N, ran on a AMD Ryzen 5 7600, compiled with -Ofast`}},
                xaxis: {title: {text: "N"}},
                yaxis: {title: {text: "mean time (ms)"}},
            }
        )
    }
    const select = document.getElementById("select_plot_data")
    fetch_data(`resources/${select.value}_rel_5_filtered_data.json`)
    const label = document.getElementById('num_threads');
    select.addEventListener("input", (event) => {fetch_data(`resources/${event.target.value}_rel_5_filtered_data.json`); label.textContent =  select.value })
    label.textContent = select.value
</script>
<div class="paragraph">
<p>O que poderia ter causado essa tamanha disparidade entre a versão por task e a versão por for? Duas coisas: o overhead
de tasks em geral (criação, scheduling, e comunicação personalizada do resultado pela fila <code>pending_values</code>), que apesar
de se restringirem aos números primos, não compensam por sua granularidade (o custo adicional da task é significativo
comparado à carga); e a uma falha na premissa da implementação: ao se considerar que podem ser geradas novas tasks sem
ter que esperar as demais tasks, pode ser natural pensar que as primeiras tasks a serem criadas seriam as primeiras
tasks a serem resolvidas. Este não é o caso — o OpenMP não impõe nenhuma prioridade às tasks por padrão, e alternativas
para dar essa prioridade, como a cláusula <code>priority</code>, são de implementação opcional. Com isso, o ponto positivo da
abordagem com tasks fica dependente das chances de se ter a primeira task da fila resolvida antes que as demais tasks
acabem. Aqui, torcer para que criem uma especificação definindo uma cláusula para agendamento fifo das tasks para o
OpenMP e que ela seja implementada pelo seu compilador é o que resta.</p>
</div>
<div class="paragraph">
<p>Bônus: se você sabe um pouco de C++ e ficou se perguntando o porquê de eu usar um array de booleanos ao invés de um
<code>vector&lt;bool&gt;</code> (ou só ficou se perguntando se não daria para codificar os 8 números para cada byte do array ao invés de
1:1), são dois fatores: a manipulação de máscaras de bit aumentaria o custo para marcar um número (que até aí poderia
ser remediável com batches de 8 números por vez), e para poder operar no array sem a necessidade de sincronização — se
cada byte guardasse múltiplos valores, teríamos o mesmo problema observado em <code>prime_count</code> durante a aplicação das
máscaras.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_relacionados_5">Relacionados</h3>
<div class="ulist">
<ul>
<li>
<p>É complicado falar da história de qualquer coisa (com credibilidade) sem ter fontes e frequentemente faço isso nas
introduções, mas não faço muita pesquisa ou fact-checking desses fatos: quase tudo é um "vi em algum lugar e tive
curiosidade sabe-se lá quanto tempo atrás" que lembro e uso. As inspirações (e também parte dos recursos que consigo
traçar) são coisas como <a href="https://ieeexplore.ieee.org/document/1447203">o próprio artigo que trouxe a Taxonomia de
Flynn</a>, <a href="https://arxiv.org/pdf/2203.02544">o overview histórico deste artigo do Dongarra (ele tem lançado versões diferentes desse artigo tem um tempo, a final se não me engano foi pra ACM, mas esse tem mais conteúdo)</a> e <a href="https://www.youtube.com/playlist?list=PLKtxx9TnH76QV56t5_ty1TDWQ2xmv75bs">os vídeos de história dos computadores desse canal (Asianometry)</a>.</p>
</li>
<li>
<p>A versão paralela em Rust <a href="https://wannesmalfait.github.io/blog/2024/parallel-primes/">desta postagem</a> foi por onde
vi primeiro sobre a independência da marcação de um número N em relação aos números que sucedem sua raiz.</p>
</li>
<li>
<p>Como este é o início da parte com programação paralela de fato, alguns materiais como o
<a href="https://rookiehpc.org/openmp/index.html">RookieHPC</a>,
<a href="https://www.archer2.ac.uk/training/courses/210000-openmp-self-service/">este curso do supercomputador britânico
archer2</a>, <a href="https://hpc-tutorials.llnl.gov/openmp/">o tutorial de OpenMP do LLNL (o lab. da introdução!)</a> e o próximo
item da listagem;</p>
</li>
<li>
<p>Os dois livros de programação paralela que mencionei na postagem passada continuam relevantes (são até mais para essa postagem!) <a href="https://www.casadocodigo.com.br/products/livro-programacao-paralela">O livro feito por brasileiros, em
português</a>, <a href="https://www.amazon.com/Introduction-Parallel-Programming-Peter-Pacheco/dp/0128046058">e o livro do
Pacheco</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_íntegra_dos_códigos_5">Íntegra dos códigos</h3>
<details>
<summary class="title">main.cpp</summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c++ hljs" data-lang="c++">#include &lt;cstdio&gt;
#include &lt;unordered_map&gt;
#include &lt;string&gt;
#include &lt;cerrno&gt;
#include "utils.h"
#include &lt;cmath&gt;
#include &lt;omp.h&gt;

//today is a nice day to throw off size_t and go back to use unsigned long. who knows, maybe ill go to uint64_t again

/*
    the idea is to make a Sieve of Erastosthenes operating in a odd number array to save memory. as such, we could map
    the array indexes to the natural numbers with a function N:N i -&gt; 2*i +1, but in such the index 0 would map to 1,
    which we usually already skip by starting at 2 (that we also skip as we are searching only on odd numbers),
    so we would either need to waste a byte with the first position of the array or we would need to shift it by -1 on
    every access. To prevent it, we just shift the whole function by 1, making it N:N i - &gt; 2*(i+1) +1 = 2*i +3.
    With it we get rid of the subtraction in every memory access and only change a constant value that would be summed
    up on the loop condition.
*/

/*
    Given a odd number j, it's index in the odd_integer_field is (j-1)/2 -1; so it's square, which is also odd, is
    (j^2 -1)/2 -1. subtracting j^2 index by j gives us it's offset in the odd_integer_field, which equals j(j-1)/2.
    substituting j by it's index based formula, j = 2*(i+1) + 1, we have that the offset between a odd number at index i
    and it's square is 2(i^2) + 5i +3. In a similar fashion, given a odd number X and its next odd multiple 3X, the
    index offset is X which, in function of X's index Y, is 2*Y+3
*/

//alternatively, you could try parallelizing the following (sketch on regular index but could be done on odd-only just
//fine):
/*
    //you'll prolly need to make separate arrays for counter and targets to vectorization
    struct {unsigned long counter, unsigned long prime_target} array[N/log(N)];
    array[0] = {1, 2};
    unsigned long prime_count = 1;
    for (unsigned long i = 2; i &lt;= N; i++){
        bool is_prime = true;
        for (unsigned long j = 0; j &lt; prime_count; j++){
            array[j].count++;
            if (array[j].count == array[j].target){
                is_prime = false;
                array[j].count == 1;
                break;
            }
        }
        if (is_prime){
            array[prime_count] = {1, i};
            prime_count++;
        }
    }
*/
//the same task vs parallel for comparison would happen here, but you would have trouble sharing the counters.
//the early return and vectorization together on the loop over counters also don't match well (though i guess they would
//be better than each of them individually for big enough numbers)

//making my own queue 'cause std::queue's memory management was giving me a hard time
//template &lt;typename T&gt;
template &lt;typename T&gt;
struct minimal_queue {
    T* front = nullptr;
    T* end = nullptr;
    T* push(T value);
    T pop();
    bool empty() const {return size == 0;};
    unsigned long size = 0;
    unsigned long start_offset = 0;
    const unsigned long max_elements;
    T* const buffer;
    minimal_queue(unsigned long max_elements) : max_elements(max_elements), buffer(new T[max_elements]){}
    ~minimal_queue(){delete[] buffer;}
};

//leaving push() to a full queue as UB, check size first
template &lt;typename T&gt;
T* minimal_queue&lt;T&gt;::push(T value){
    T* const ptr = this-&gt;buffer + ((this-&gt;start_offset + this-&gt;size)%this-&gt;max_elements);
    *ptr = value;
    if (this-&gt;empty()){
        this-&gt;front = ptr;
    }
    this-&gt;end = ptr;
    this-&gt;size++;
    return ptr;
}

//leaving a pop() to an empty queue as UB, check empty() first
template &lt;typename T&gt;
T minimal_queue&lt;T&gt;::pop(){
    T value = *(this-&gt;front);
    if (size == 1){
        this-&gt;front = nullptr;
        this-&gt;end = nullptr;
    } else{
        this-&gt;front = this-&gt;buffer + ((this-&gt;start_offset+1)%this-&gt;max_elements);
    }
    this-&gt;size--;
    this-&gt;start_offset = (this-&gt;start_offset+1)%this-&gt;max_elements;
    return value;
}

enum PRINT_MODE {
    REGULAR,
    CSV
};


std::unordered_map&lt;std::string, PRINT_MODE&gt; print_flags = {
    {"-printCSV", CSV},
};

typedef utils::_return_data&lt;unsigned long&gt; return_data;

inline unsigned long i_val_square_index(unsigned long i){
    return 2*i*i + 6*i + 3;
}
inline unsigned long i_odd_multiples_incr(unsigned long i){
    return 2*i +3;
}

typedef struct task_info_struct {
    unsigned long value;
    bool done;
} task_info;

typedef struct minimal_queue&lt;task_info&gt; task_queue;

inline void mark_multiples(unsigned long base_index, unsigned long N, bool* odd_integer_field){

    unsigned long start = i_val_square_index(base_index); //base_index + square offset
    unsigned long incr = i_odd_multiples_incr(base_index);
    unsigned long limit = (N-3)/2;
    for (unsigned long i = start; i &lt;= limit; i+= incr){
        odd_integer_field[i] = true;
    }
}

//num_threads kept here just to keep a uniform interface with the parallel functions
return_data count_primes_serial(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    for (unsigned long i = 0; i &lt;= N_in_odd_index; i++){
        if (!odd_integer_field[i]){
            mark_multiples(i, N, odd_integer_field);
            prime_count++;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}

return_data count_primes_naive_parallel(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    #pragma omp parallel for num_threads(num_threads)
    for (unsigned long i = 0; i &lt;= N_in_odd_index; i++){
        if (!odd_integer_field[i]){
            mark_multiples(i, N, odd_integer_field);
            prime_count++;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}

return_data count_primes_task(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    task_queue pending_values = {(unsigned long) (N/std::log(N))};
    unsigned long N_in_odd_index = (N-3)/2;
    //omp seems to have no fifo priority for tasks so
    unsigned long prio = omp_get_max_task_priority();
    auto start = utils::mark_time();

    #pragma omp parallel num_threads(num_threads)
    {
        #pragma omp single
        {
            unsigned long i = 0;
            unsigned long last_index = 1; //just putting a different value
            unsigned long progress_threshold = i_val_square_index(i)-1;
            while (i &lt;= N_in_odd_index){
                if (i != last_index){
                    if (!odd_integer_field[i]){
                        task_info* pending_task = pending_values.push({i, false});
                        #pragma omp task firstprivate(pending_task) priority(prio)
                        {
                            mark_multiples(pending_task-&gt;value, N, odd_integer_field);
                            pending_task-&gt;done = true;
                        }
                        prio = (prio-1)==0 ? 1 : prio-1;
                        prime_count++;
                    }
                }
                last_index = i;
                
                if (!pending_values.empty()){
                    if (pending_values.front-&gt;done){
                        progress_threshold = i_val_square_index(pending_values.pop().value)-1;
                    }
                }
                i = i+1 &lt; progress_threshold ? i+1 : progress_threshold;
            }
        }
    }
    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}

return_data count_primes_for_dynamic(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    #pragma omp parallel num_threads(num_threads) reduction(+:prime_count)
    {
        prime_count = 0;
        for (unsigned long i = 0; i &lt;= N_in_odd_index;){
            unsigned long progress_threshold = i_val_square_index(i)-1;
            progress_threshold = progress_threshold &gt; N_in_odd_index ? N_in_odd_index : progress_threshold;
            unsigned long partition_size = (progress_threshold-i)/(12*num_threads);
            partition_size = partition_size == 0 ? 1 : partition_size;
            #pragma omp for schedule(dynamic,partition_size)
            for (unsigned long j = i; j &lt;= progress_threshold; j++){
                if (!odd_integer_field[j]){
                    mark_multiples(j, N, odd_integer_field);
                    prime_count++;
                }
            }
            i = progress_threshold + 1;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}

return_data count_primes_for_static(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    #pragma omp parallel num_threads(num_threads) reduction(+:prime_count)
    {
        prime_count = 0;
        for (unsigned long i = 0; i &lt;= N_in_odd_index;){
            unsigned long progress_threshold = i_val_square_index(i)-1;
            progress_threshold = progress_threshold &gt; N_in_odd_index ? N_in_odd_index : progress_threshold;
            unsigned long partition_size = (progress_threshold-i)/(12*num_threads);
            partition_size = partition_size == 0 ? 1 : partition_size;
            #pragma omp for schedule(static,partition_size)
            for (unsigned long j = i; j &lt;= progress_threshold; j++){
                if (!odd_integer_field[j]){
                    mark_multiples(j, N, odd_integer_field);
                    prime_count++;
                }
            }
            i = progress_threshold + 1;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}

return_data count_primes_for_guided(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    #pragma omp parallel num_threads(num_threads) reduction(+:prime_count)
    {
        prime_count = 0;
        for (unsigned long i = 0; i &lt;= N_in_odd_index;){
            unsigned long progress_threshold = i_val_square_index(i)-1;
            progress_threshold = progress_threshold &gt; N_in_odd_index ? N_in_odd_index : progress_threshold;
            unsigned long partition_size = (progress_threshold-i)/(12*num_threads);
            partition_size = partition_size == 0 ? 1 : partition_size;
            #pragma omp for schedule(guided)
            for (unsigned long j = i; j &lt;= progress_threshold; j++){
                if (!odd_integer_field[j]){
                    mark_multiples(j, N, odd_integer_field);
                    prime_count++;
                }
            }
            i = progress_threshold + 1;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}

return_data count_primes_for_auto(unsigned long N, unsigned long num_threads){

    bool* odd_integer_field = (bool*)calloc(N/2 +1, sizeof(bool));
    unsigned long prime_count = (N &gt;= 2) ? 1 : 0;
    unsigned long N_in_odd_index = (N-3)/2;
    auto start = utils::mark_time();

    #pragma omp parallel num_threads(num_threads) reduction(+:prime_count)
    {
        prime_count = 0;
        for (unsigned long i = 0; i &lt;= N_in_odd_index;){
            unsigned long progress_threshold = i_val_square_index(i)-1;
            progress_threshold = progress_threshold &gt; N_in_odd_index ? N_in_odd_index : progress_threshold;
            unsigned long partition_size = (progress_threshold-i)/(12*num_threads);
            partition_size = partition_size == 0 ? 1 : partition_size;
            #pragma omp for
            //#pragma omp for
            for (unsigned long j = i; j &lt;= progress_threshold; j++){
                if (!odd_integer_field[j]){
                    mark_multiples(j, N, odd_integer_field);
                    prime_count++;
                }
            }
            i = progress_threshold + 1;
        }
    }

    auto end = utils::mark_time();
    free(odd_integer_field);
    return {prime_count, utils::calc_time_interval_ms(start, end)};
}
typedef return_data (*target_func_ptr)(unsigned long, unsigned long);

//those extra modes were used very briefly to decide which schedule to use, might be present on the post if i've got
//time remaining
std::unordered_map&lt;std::string, target_func_ptr&gt; modes = {
    {"SERIAL", count_primes_serial},
    {"NAIVE_PARALLEL", count_primes_naive_parallel},
    {"TASK_PARALLEL", count_primes_task},
    {"LOOP_PARALLEL_STATIC", count_primes_for_static},
    {"LOOP_PARALLEL_DYNAMIC", count_primes_for_dynamic},
    {"LOOP_PARALLEL_GUIDED", count_primes_for_guided},
    {"LOOP_PARALLEL_AUTO", count_primes_for_auto},
};

int main(int argc, char* argv[]){
    PRINT_MODE print_mode = REGULAR;
    if (argc &lt; 4){
        printf("Insufficient arguments, use: %s &lt;MODE&gt; &lt;MAX_NUMBER&gt; &lt;NUM_THREADS&gt; [-printCSV]\n", argv[0]);
        printf("&lt;MODE&gt; being SERIAL, NAIVE_PARALLEL, TASK_PARALLEL, LOOP_PARALLEL_STATIC, LOOP_PARALLEL_DYNAMIC, LOOP_PARALLEL_GUIDED, LOOP_PARALLEL_AUTO\n");
        exit(1);
    } else{
        if (argc &gt; 5) {
            printf("Too many arguments starting at %s. Use: %s &lt;MODE&gt; &lt;MAX_NUMBER&gt; &lt;NUM_THREADS&gt; [-printCSV]\n",
                argv[5], argv[0]);
            exit(1);
        }
        if (argc == 5){
            auto temp_print = print_flags.find(argv[4]);
            if (temp_print == print_flags.end()){
                printf("Invalid argument: %s. Usage: %s &lt;MODE&gt; &lt;MAX_NUMBER&gt; &lt;NUM_THREADS&gt; [-printCSV]\n",
                    argv[4], argv[0]);
                exit(1);
            }
            print_mode = temp_print-&gt;second;
        }
    }

    auto mode = modes.find(argv[1]);
    if (mode == modes.end()){
        printf("Invalid mode: %s. Choose between SERIAL, NAIVE_PARALLEL, TASK_PARALLEL, LOOP_PARALLEL_STATIC, LOOP_PARALLEL_DYNAMIC, LOOP_PARALLEL_GUIDED, LOOP_PARALLEL_AUTO\n", argv[1]);
        exit(1);
    }

    target_func_ptr func = mode-&gt;second;

    size_t params[2];
    for (auto i = 0; i &lt; 2; i++){
        params[i] = std::strtoul(argv[2+i], NULL, 10);
        if (params[i] == 0 || errno == ERANGE){
            printf("Invalid parameter: %s.\n", argv[2+i]);
            exit(1);
        }
    }

    return_data exec_data = mode-&gt;second(params[0], params[1]);

    switch (print_mode)
    {
    case CSV:
        printf("%s,%lu,%lu,%lu,%f\n", argv[1], params[0], params[1], exec_data.res, exec_data.time_ms);
        break;
    default:
        printf("Result for n = %lu: %lu; Total elapsed time: %f ms\n", params[0], exec_data.res, exec_data.time_ms);
        break;
    }

    return 0;
}</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title">run_tests.sh</summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">EXEC_FILE="./a.out"
PYTHON_EXEC=python3

RUN_MODES="too_lazy_to_remove"
START_THREADS=1
MAX_THREADS=12

#alternating modes manually
GENERAL_MODES="SERIAL NAIVE_PARALLEL"
PROBLEM_SIZE=10
MAX_PROBLEM_SIZE=50

#block 2 - comment/uncomment to change mode
#GENERAL_MODES="TASK_PARALLEL LOOP_PARALLEL_DYNAMIC"
#PROBLEM_SIZE=10
#MAX_PROBLEM_SIZE=100000000 #10^8
#START_THREADS=2

GROWTH_FACTOR=0.5

regular_scale_problem_size() {
    PROBLEM_SIZE=$($PYTHON_EXEC -c "import math; print($PROBLEM_SIZE + int(max((10**math.log10($PROBLEM_SIZE)//10)*$GROWTH_FACTOR, 5)))")
}

NUM_SAMPLES=5
OUTPUT_FILE=$1
STATUS=0

if [ -z "$OUTPUT_FILE" ]
then
    echo "Pass the path to an output file, use: $0 &lt;path/to/output&gt;"
    exit
fi
echo MODE,MAX_NUMBER,NUM_THREADS,PRIME_COUNT,TIME_MS &gt; $OUTPUT_FILE

while [ "$PROBLEM_SIZE" -le "$MAX_PROBLEM_SIZE" ]
do
    for MODE in $GENERAL_MODES
    do
        SAMPLE=1
        while [ "$SAMPLE" -le "$NUM_SAMPLES" ]
        do
            for RMODE in $RUN_MODES
            do
                THREADS=$START_THREADS
                TARGET_THREADS=$MAX_THREADS
                if [ "$MODE" = "SERIAL" ]
                then
                    TARGET_THREADS=1
                fi
                while [ "$THREADS" -le "$TARGET_THREADS" ]
                do
                    #tis one of the few places where such dquotes matching would be okay and allowed
                    echo running "$EXEC_FILE $MODE $PROBLEM_SIZE $THREADS -printCSV &gt;&gt; $OUTPUT_FILE"
                    $EXEC_FILE $MODE $PROBLEM_SIZE $THREADS -printCSV &gt;&gt; $OUTPUT_FILE
                    STATUS=$?
                    if [ "$STATUS" -ne 0 ]
                    then
                        #intended for when the MAT_SIDE is too big for the program to allocate this much memory
                        echo Some error occurred, stopping early.
                        exit
                    fi
                    THREADS=$(($THREADS+1))
                done
            done
            SAMPLE=$(($SAMPLE+1))
        done
    done
    regular_scale_problem_size
done</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title">process_data.py</summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import pandas as pd
import matplotlib.pyplot as plt
import sys
import os

if len(sys.argv) &lt; 4: print(f"Too few arguments, use {sys.argv[0]} &lt;input_filepath&gt; &lt;img_output_suffix&gt; &lt;output_suffix&gt; [-basic]"); exit(0)
if len(sys.argv) &gt; 5: print(f"Too many arguments, use {sys.argv[0]} &lt;input_filepath&gt; &lt;img_output_suffix&gt; &lt;output_suffix&gt; [-basic]"); exit(0)

data = pd.read_csv(sys.argv[1])

if len(sys.argv) == 5:
    if sys.argv[4] == "-basic":
        data = data[(data['MAX_NUMBER']==10) | (data['MAX_NUMBER']==50)]
        data = data[data['NUM_THREADS'] &lt;= 6]
        data = data.groupby(['MODE', 'MAX_NUMBER', 'NUM_THREADS']).aggregate(
            {
                "PRIME_COUNT": ['mean', 'var'],
                "TIME_MS": 'mean'
            }
        ).unstack('NUM_THREADS')

        data.columns = data.columns.swaplevel(0,2)
        data.columns = data.columns.swaplevel(1,2)

        data = data.sort_index(axis=1)#.reset_index(level='')

        data.to_csv(sys.argv[3], float_format="%.6g")

        #can't differentiate indexes to merge, maybe adding a index list of which lines to merge?
        def csv_line_to_asciidoc(_line, sep=",", merge=True):
            line = _line
            if _line.endswith("\n"): line = _line[:-1]
            skip_tuple_token = (None, None)
            new_line = []
            ipair_line = list(enumerate(line.split(sep)))
            for i, word in ipair_line:
                if i is None:
                    continue
                rep_count = 0
                if merge or word == '':
                    for j, next_word in ipair_line[i+1:]:
                        if next_word != word:
                            if next_word != '':
                                break
                        rep_count += 1
                        ipair_line[j] = skip_tuple_token
                if rep_count == 0:
                    new_line.append(f"|{word}\n")
                else:
                    new_line.append(f"{rep_count+1}+|{word}\n")
            new_line[-1] = new_line[-1][:-1] + "  \n" 
            return "".join(new_line)
                
        merge_indexes = [0, 1]
        for i,line in enumerate(open("sys.argv[3]").readlines()):
            print(csv_line_to_asciidoc(line, merge=i in merge_indexes))
        exit(0)
    else:
        print(f"Invalid parameter: {sys.argv[4]}")
        exit(1)



data = data.drop(columns=['PRIME_COUNT']).groupby(['MODE', 'MAX_NUMBER', 'NUM_THREADS'], as_index=False).mean()
size = (16,9)
fig, ax = plt.subplots(figsize=size)

thread_vals = pd.unique(data['NUM_THREADS'])

def make_plot(data):

    comp_plots_data = {num_threads:{} for num_threads in thread_vals}

    for num_threads in thread_vals:
        filtered = data[data['NUM_THREADS']==num_threads]
        #comp_plots_data[num_threads]["div_scale"] = filtered['TIME_MS'].max()
        for mode in pd.unique(filtered['MODE']):
            filtered_2 = filtered[filtered['MODE']==mode]
            if len(filtered_2) == 0: print(f"Empty for {num_threads} and {mode}!"); continue
    
            comp_plots_data[num_threads][mode] = {"x": [x for x in filtered_2['MAX_NUMBER']],
                "y": [x for x in filtered_2['TIME_MS']]}

    counter = 0
    for num_threads in comp_plots_data:
        fig, ax = plt.subplots(figsize=size)
        minval_x = float("inf")
        maxval_x = -float("inf")
        for mode in comp_plots_data[num_threads]:
            ax.plot(comp_plots_data[num_threads][mode]["x"], comp_plots_data[num_threads][mode]["y"],
                    label=f"{mode}", linestyle=":" if counter%2 == 0 else "-.")
            minval_x = min(minval_x, min(comp_plots_data[num_threads][mode]['x']))
            maxval_x = max(maxval_x, max(comp_plots_data[num_threads][mode]['x']))
            counter +=1
        ax.set_xlabel('N')
        ax.set_ylabel('Mean time (ms)')
        ax.set_title("5 samples per N, ran on a AMD Ryzen 5 7600, compiled with -Ofast")
        ax.legend()
        ax.set_xlim(left=minval_x, right=maxval_x)
        fig.suptitle(f"Timings for {num_threads} threads")
        plt.tight_layout()
        fig.savefig(f"{num_threads}_{sys.argv[2]}")
        pd.DataFrame(comp_plots_data[num_threads]).to_json(f"{num_threads}_{sys.argv[3]}")

make_plot(data)</code></pre>
</div>
</div>
</div>
</details>
</div>
</div>
</div>
<div class="paragraph nav-footer">
<p>← Previous: <a href="multithreading-e-threads-de-hardware.html">Threading por hardware e hyperthreading</a> | ↑ Up: <a href="index.html">Programação Paralela</a> | Next: <a href="paralelismo-threads-openmp-escopos-critical.html">Paralelismo por Threads com OpenMP: Escopo e seções críticas</a> →</p>
</div>
</div>
<div id="footer" style="max-width: 80%;">
<div id="footer-text">
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>