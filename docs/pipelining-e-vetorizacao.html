<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<meta name="author" content="Marcos Irigoyen">
<title>Programação Paralela</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/styles/github.min.css">
<style>.toc-current{font-weight: bold;} .toc-root{font-family: "Open Sans","DejaVu Sans",sans-serif;
                       font-size: 0.9em;} #content{display: flex; flex-direction: column; flex: 1 1 auto;}
             .nav-footer{text-align: center; margin-top: auto;}
             .nav-footer > p > a {white-space: nowrap;}</style>
</head>
<body id="pipelining-e-vetorizacao" class="book toc2 toc-left text-justify">
<div id="header" style="max-width: 80%;">
<h1>Programação Paralela</h1>
<div class="details">
<span id="author" class="author">Marcos Irigoyen</span><br>
<span id="email" class="email"><a href="mailto:mvbirigoyen@gmail.com">mvbirigoyen@gmail.com</a></span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Sumário</div>
<p><span class="toc-root"><a href="index.html">Programação Paralela</a></span></p><ul class="sectlevel1">
<li><a href="gargalo-de-von-neumann.html">Gargalo de Von Neumann e a Cache</a>
</li>
<li><a href="pipelining-e-vetorizacao.html"><span class="toc-current">Pipelining e Vetorização</span></a>
<ul class="sectlevel2">
<li><a href="pipelining-e-vetorizacao.html#_introdução_2">Introdução</a>
</li>
<li><a href="pipelining-e-vetorizacao.html#_experimento">Experimento</a>
</li>
<li><a href="pipelining-e-vetorizacao.html#_resultado">Resultado</a>
</li>
<li><a href="pipelining-e-vetorizacao.html#_relacionados_2">Relacionados</a>
</li>
<li><a href="pipelining-e-vetorizacao.html#_íntegra_dos_códigos_2">Íntegra dos códigos</a>
</li>
</ul>
</li>
<li><a href="fontes-de-demanda-por-performance-precisao.html">Fontes de demanda por performance: precisão</a>
</li>
<li><a href="multithreading-e-threads-de-hardware.html">Threading por hardware e hyperthreading</a>
</li>
<li><a href="paralelismo-threads-openmp-for.html">Paralelismo por Threads com OpenMP</a>
</li>
<li><a href="paralelismo-threads-openmp-escopos-critical.html">Paralelismo por Threads com OpenMP: Escopo e seções críticas</a>
</li>
<li><a href="paralelismo-threads-openmp-tasks.html">Paralelismo por Threads com OpenMP: Tasks</a>
</li>
</ul>
</div>
</div>
<div id="content" style="max-width: 80%;">
<div class="sect1">
<h2 id="pipelining-e-vetorizacao">Pipelining e Vetorização</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_introdução_2">Introdução</h3>
<div class="paragraph">
<p>Se você viu a postagem anterior, pode ter se perguntando: "por que o algoritmo otimizado para matrizes alinhadas por
coluna era mais rápido que o normal, otimizado para alinhamento por linha?" e, se fingirmos que não dá para ler o título
desse post, poderíamos pensar ainda que o esperado era de que o algoritmo normal fosse mais rápido, visto que cada
\(c_i\) calculado só precisava de uma lida e escrita do elemento no vetor de saída na memória a cada iteração,
enquanto que cada elemento da saída era lido e escrito N+1 vezes no algoritmo alternativo, onde N é o número de
elementos do vetor de saída. O que o leitor hipotético que pensou demais na quantia de acessos do vetor de saída não
pensou, entretanto, são nas demais técnicas que os processadores empregam para acelerar o processamento de instruções.
Neste caso, a funcionalidade central na obtenção do ganho é a de pipelining de instruções. Será abordado o funcionamento
do pipelining e execução em blocos, para então seguirmos a vetorização/instruções SIMD, compiladores e assembly.</p>
</div>
<div class="sect3">
<h4 id="_pipelining">Pipelining</h4>
<div class="paragraph">
<p>Para explicar pipelining, vale um resumo de como processadores executam instruções. Assumindo um modelo simplificado, de
execução serial da instruções e tempos de acesso desprezíveis, temos quatro etápas para execução de uma instrução:
busca, decodificação, execução, e armazenamento. Durante a execução de uma instrução neste processador básico, as
componentes relacionadas a cada etapa ou sub-etapa que não esteja sendo ativamente executada em dado ciclo do
processador não são aproveitadas, sendo necessário a espera de toda a execução de uma instrução para o começo da
próxima. Para solucionar este problema surge o pipelining, adicionando buffers entre as etapas/sub-etapas de execução,
de forma que suas componentes possam ser utilizadas logo após seu uso, possibilitando a execução de múltiplas
instruções simultaneamente em um único processador (um único core de processador, considerando multi-cores).</p>
</div>
<div class="paragraph">
<p>Este multiprocessamento, entretanto, é naturalmente limitado pela ordem de execução das instruções e suas
interdependências. Não se pode realizar uma operação baseada no resultado de outra que ainda não foi armazenada, por
exemplo. Para remediar isso tanto processadores quanto compiladores procuram otimizar a ordem de execução das instruções
para maximizar o aproveitamento do pipelining sem alterar o "espírito" do código. No contexto do produto entre matriz e
vetor apresentado na última postagem, a implementação para matrizes alinhadas por linha tinha a dependência da conclusão
de todas as multiplicações entre elementos anteriores do vetor linha e vetor de entrada E seus respectivos incrementos
no elemento do vetor de saída para que se pudesse incrementar o resultado da multiplicação seguinte; enquanto que o
algoritmo otimizado para matrizes alinhadas conseguia começar a ponderação do vetor coluna por seu respectivo escalar do
vetor de entrada e seu incremento ao vetor de saída independentemente.</p>
</div>
<div class="paragraph">
<p>A execução de múltiplas instruções independentes entre si ao mesmo tempo por pipelining foi um avanço significante no
desempenho de processadores (que conforme será mostrado, ainda rende muita performance atualmente) que não é fruto
direto de melhorias no processo de fabricação (diminuição do tamanho de transistores, empacotamento, e outros
contribuintes à lei de Moore e a antiga escala de Dennard), mas de avanços no design e arquitetura dos computadores.
Não raramente, entretanto, tem-se a situação onde as várias instruções a serem executadas se tratam da mesma instrução,
aplicada a dados diferentes — operações matriciais, como as do exemplo anterior, são casos desse tipo. Pela extensa
presença desse padrão de processamento em aplicações numéricas, eventualmente surgiram nos supercomputadores a
capacidade de processar múltiplos dados a partir da mesma instrução, adicionando mais componentes responsáveis pela
execução da instrução ao processador. Daí surgiram os atualmente sumidos computadores vetoriais (veja o Fugaku para o
mais próximo <span class="line-through">que eu sei</span> disso na atualidade) e a ideia de vetorização.</p>
</div>
</div>
<div class="sect3">
<h4 id="_vetorização">Vetorização</h4>
<div class="paragraph">
<p>Como no final da sessão acima, a vetorização se dá pela execução simultânea de uma instrução sobre diferentes dados.
Mais especificamente, se tratam de instruções que operam sobre registradores especiais (especiais, mas que podem ser
usados como registradores normais) capazes de abrigar múltiplos dados de forma que os dados contidos nestes
registradores sejam processados paralelamente. As restrições sofridas no pipelining são herdadas pela vetorização, ainda
acrescidas de fatores como a limitação de operações possíveis de se vetorizar e a responsabilidade pelo lado da
aplicação de aplicar as instruções. Este último, conforme novos padrões de instruções vetoriais são lançados, conflita
com objetivos como o reaproveitamento de programas compilados em múltiplas máquinas, para além de exigir esforços de
desenvolvimento para integração dessas instruções em compiladores, interpretadores (ainda que td seja JIT) ou, quando
as heurísticas desses dois não funcionam, na aplicação (a máxima disso é o ffmpeg, onde adoram falar que fazem isso).</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_experimento">Experimento</h3>
<div class="paragraph">
<p>Para demonstrar o efeito de otimizar um código para usar pipelining e/ou vetorização, poderíamos pegar o algoritmo
convencional de multiplicação matriz-vetor da postagem passada, implementá-lo com o que vou explicar ser "desenrolamento
de loop", e comparar com o orignal e o algoritmo alternativo para colunas. O requisito da atividade pede outra coisa,
então isso fica de exercício para o leitor. Para demonstrar o efeito de otimizar um código para usar pipelining e/ou
vetorização, vamos fazer uma comparação simples com implementações de uma função que retorne a soma de todos os valores
de um vetor (e também com o tempo que demora para preenchê-lo com algum cálculo simples). A forma mais simples desse
algoritmo se resume a criar uma variável (acumulador) inicializada em zero e iterar pelo vetor somando à variável o
valor de cada elemento. Aqui, como no §2 de Pipelining, cada instrução de incremento do valor de um elemento ao
acumulador é dependente da resolução dessa instrução com os elementos anteriores, impossibilitando o aproveitamento do
pipelining e/ou vetorização.</p>
</div>
<div class="paragraph">
<p>Para solucionar isso, podemos "desenrolar" o loop, reduzindo o número de iterações e adicionando, em cada iteração, o
processamento de mais elementos. Para isso, vamos transformar algumas coisas: ao invés de iterar por elementos do vetor,
vamos considerar iterar por blocos do vetor, onde cada bloco equivale a um determinado número de elementos. Assumindo
que o tamanho do vetor é divisível exatamente pelo tamanho do bloco, iterar por R blocos do vetor (sendo R a razão entre
o tamanho do vetor e o tamanho do bloco) e realizar a operação para cada elemento do vetor. Para a soma dos elementos do
vetor por um elemento de cada vez (que também poderia ser entendido como um bloco de tamanho 1), temos algo como:</p>
</div>
<div class="listingblock">
<div class="title">Exemplo de soma um a um para um vetor de inteiros (int)</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">int somar_tudo(int* vetor_in, int tamanho){
    int resultado = 0;
    for (int i = 0; i &lt; tamanho; i++){
        resultado += vetor_in[i];
    }
    return resultado;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Enquanto que, fazendo para um bloco de tamanho 2, teríamos:</p>
</div>
<div class="listingblock">
<div class="title">Exemplo de soma em bloco de tamanho 2 para um vetor de inteiros (int)</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">int somar_tudo_bloco_2(int* vetor_in, int tamanho){
    int acumulador1 = 0;
    int acumulador2 = 0;
    int resultado = 0;

    int i = 0; //declarando o i fora do loop para reaproveitar ele pro resto da divisão
    //você só pode passar esse (2-1) pro lado direito da inequação se usar inteiro sinalado (besteira de impl.)
    for (; i + (2 - 1) &lt; tamanho; i += 2){
        acumulador1 += vetor_in[i];
        acumulador2 += vetor_in[i+1];
    }
    //tratando o resto da divisão um a um
    for (; i &lt; tamanho; i++){
        resultado += vetor_in[i];
    }
    resultado += acumulador1 + acumulador2;
    return resultado;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Extra: antes de todas essas considerações de pipelining e vetorização, já havia um tradeoff entre o overhead do loop
(execução dos jumps e checagem da condição de parada para cada iteração) e o tamanho do programa compilado, numa
situação parecida com o balanceamento do uso de funções inline. A lógica do loop aí dependeria da resolução do acesso ao
vetor para que possa começar sua execução, então boa parte desse impacto seria amortecido pelo pipelining com a soma ao
acumulador. Enquanto que isso é especulação minha, você pode gerar o assembly no gcc com o parâmetro -S, jogar em um
simulador de processador com pipeline (salve DrMIPS), e me mandar um e-mail dizendo se estou equivocado.</p>
</div>
<div class="paragraph">
<p>Por conta do já mencionado problema de compatibilidade binária consequente dos diferentes padrões de instruções
vetoriais por aí, compiladores como o GCC (que é o compilador padrão desses experimentos) não costumam usar vetorização
por padrão. Aproveitando(?) isso, o experimento será repetido com as flags de otimização O0, O2 e O3, e todas com a flag
-march=native, que sinaliza para o GCC compilar o código para ser executado especificamente na arquitetura do
processador do computador. Para avisos sobre a quando e onde ocorre vetorização, é usada a flag -fopt-info-vec, mas como
cada função foi implementada por meio de um template, não se pode discernir qual função foi otimizada (todas apontam
para a mesma linha, se você souber como contornar isso, por favor me avise).</p>
</div>
<div class="paragraph">
<p>Para clarificação, a flag O0 desativa quase todas as otimizações, enquanto que a O2 usa todas as otimizações que não
tenham um tradeoff entre tamanho do binário e velocidade de execução (logo não vetoriza ou desenrola loops) e a O3
habilita as demais otimizações que ainda seriam "standard-compliant para todos os programas".</p>
</div>
</div>
<div class="sect2">
<h3 id="_resultado">Resultado</h3>
<script src="https://cdn.plot.ly/plotly-3.0.1.min.js" charset="utf-8"></script>
<div id="plot_wrapper" style="display:flex; flex-direction:column">
    <div id="plot_times" style="margin:auto;width:70%;aspect-ratio: 16 / 9">Se você está vendo isso aqui, o script do plot deu pau</div>
    <select id="select_plot_data" name="Dados" style="margin:auto;width:40%">
        <option value="resources/dados_O0_filtrados.csv" selected>Compilado com -O0</option>
        <option value="resources/dados_O2_filtrados.csv">Compilado com -O2</option>
        <option value="resources/dados_O3_filtrados.csv">Compilado com -O3</option>
        <option value="resources/dados_Ofast_filtrados.csv">Bônus: Compilado com -Ofast</option>
        <option value="resources/dados_O3unlimited_filtrados.csv">Bônus: Compilado com -O3 e -fvect-cost-model=unlimited</option>
    </select>
</div>
<script>
    cache = {}
    async function fetch_data(path){
        var data = []
        if (cache[path]){data = cache[path]; console.log("omggg acertei o cache mais preguiçoso que existe")}
        else{
            const response = await fetch(path)
            const text = await response.text()
            const rows = text.split("\n").map(row => row.split(','))
            var headers = rows[0]
            const num_cols = rows[0].length
            for (var i = 1; i < rows.length; i++){
                if (rows[i].length != num_cols){continue}
                var row = {}
                for (var j = 0; j < num_cols; j++){
                    row[headers[j]] = rows[i][j]
                }
                data.push(row)
            }
            cache[path] = data
        }
        processData(data, {flag: path.split('_')[1]})
    }

    function processData(allRows, extra){
        var modes = {
            "SINGLE":{"x":[],"y":[]},
            "VEC_INIT":{"x":[],"y":[]},
            "BLOCK2":{"x":[],"y":[]},
            "BLOCK4":{"x":[],"y":[]},
            "BLOCK8":{"x":[],"y":[]},
            "BLOCK16":{"x":[],"y":[]},
        }

        for (var i=0; i < allRows.length; i++) {
            row = allRows[i];
            modes[row['MODE']]["x"].push(parseInt(row['VEC_SIZE']))
            modes[row['MODE']]["y"].push(parseFloat(row['TIME_MS']))
        }

        var dash_types = ["longdash", "dot", "dashdot"]
        var counter = 0
        for (const [key, val] of Object.entries(modes)){
            modes[key]["mode"] = "lines+markers"
            modes[key]["type"] = "scatter"
            modes[key]["name"] = key
            modes[key]["line"] = {dash:dash_types[counter]}
            counter = (counter+1)%3
            //modes[key]["mode"] =
            //modes[key]["mode"] =
        }
        document.getElementById("plot_times").innerText = ""
        var traces = Object.values(modes)
        Plotly.newPlot("plot_times", traces,
            {
                title: {text: "Vector/Array Sum-up/reduction: Time comparison between implementations", subtitle: {text: `5 samples per VEC_SIZE, float32 vectors, ran on a AMD Ryzen 5 7600, compiled with -${extra.flag}`}},
                xaxis: {title: {text: "VEC_SIZE"}},
                yaxis: {title: {text: "mean time (ms)"}, tickformat: ".5f"},
            }
        )
    }
    const select = document.getElementById("select_plot_data")
    fetch_data(select.value)
    select.addEventListener("change", (event) => {fetch_data(event.target.value)})
</script>
<div class="paragraph">
<p>Como esperado, a soma um-a-um foi a mais lenta das implementações para cada uma das flags testadas. Mais interessante
que isso, porém, é a mudança entre tamanhos de bloco ótimos de acordo com o nível de otimização: em O0, o quão menor o
tamanho do bloco, melhor é sua execução. Especula-se que pode ser fruto da falta de otimizações de reordenamento ou
direcionadas ao pipelining no O0, indo de acordo com o brusco aumento de desempenho obtido em O2 em todas as
implementações em bloco quando comparadas à singular. Pela O3 tivemos 9 vetorizações ocorrendo nas implementações. Como
todo tamanho de bloco diferente de 1 haverá dois loops (um para os blocos e outro para o resto), pode-se assumir que
cada versão em bloco contribuiu 2 vetorizações, indicando que a versão singular também conseguiu vetorização. Não seria
algo inesperado, assumindo que o compilador seja capaz de fazer o desenrolamento e então a vetorização do código, mas
indicaria uma falha nos critérios usados para decidir o tamanho do bloco utilizado, dado que o tempo de execução não viu
melhora entre as versões O2 e O3. Para os demais, o BLOCK16 foi de igual pra igual ao BLOCK8 em O2, e se manteve o
melhor no O3, mas algo estranho ocorreu às demais implementações em bloco: o tempo de execução aumentou no O3 em relação
ao O2. Pode, novamente, ser uma decisão errada no critério do O3, que por padrão insere uma checagem em tempo de
execução para avaliar se vale ou não usar vetorização.</p>
</div>
<div class="paragraph">
<p>Como teste, uma versão extra em 03 foi compilada sobrescrevendo o critério para sempre assumir como viável a
vetorização, sem testes em run-time. Não foi percebido mudança significativa no desempenho. Outra execução extra
utilizou a flag -Ofast, que completa O3 com as demais otimizações que não seriam "standard-compliant" para todos os
programas. Nela, finalmente todas as versões diferentes da mesma função eram otimizadas à mesma velocidade, próxima ao
obtido pela BLOCK16 em O3 (coletar mais amostras poderia ser interessante). P.S.: a causa provavel do melhor resultado
ser com BLOCK16 é pelos registradores vetoriais de 512 bits, que conseguiriam guardar justamente 16 floats.</p>
</div>
</div>
<div class="sect2">
<h3 id="_relacionados_2">Relacionados</h3>
<div class="ulist">
<ul>
<li>
<p>O optimize options do GCC, você pode checar por <code>gcc --help=optimizers</code> ou pela
<a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html">página do gcc</a>.</p>
</li>
<li>
<p>Em um momento considerei explicar formas com que os exemplos com matrizes poderiam ser vetorizados, usando FMA para o
algoritmo otimizado para colunas e AVX para o algoritmo otimizado para linhas. Instruções FMA são bem na cara sobre o
que fazem (Fused Multiply Add) e tem instruções pra encher um registrador vetorial com um único valor de boa, para o
caso do algoritmo por linhas, por conta do acumulador único do original, você teria que somar os valores dos
registradores entre si, e <a href="https://www.aussieai.com/book/ch30-vectorized-sum-reduction">este excerto aqui</a> chegava
exatamente nisso usando o hadd.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_íntegra_dos_códigos_2">Íntegra dos códigos</h3>
<details>
<summary class="title">main.cpp</summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c++ hljs" data-lang="c++">#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;
#include &lt;iostream&gt;
#include &lt;unordered_map&gt;
#include &lt;string&gt;
#include &lt;cerrno&gt;
#include &lt;concepts&gt;
#include &lt;type_traits&gt;
#include "utils.h"

void* _checking_malloc(size_t bytesize, int line){
    void* res = std::malloc(bytesize);
    if (res == NULL){printf("Allocation error around ln %d\n", line); exit(1);}
    return res;
}

#define checking_malloc(bytesize) _checking_malloc(bytesize, __LINE__)

template &lt;typename T&gt;
void print_vec(T* vec, size_t length){
    for (auto i = 0; i &lt; length-1; i++){
        std::cout &lt;&lt; vec[i] &lt;&lt; ", ";
    }
    std::cout &lt;&lt; vec[length-1] &lt;&lt; "\n";
}

enum PRINT_MODE {
    REGULAR,
    VECTOR,
    CSV
};

typedef utils::_return_data&lt;float&gt; return_data;

template &lt;typename T&gt;
utils::_return_data&lt;T&gt; init_vec(T* vec_in_out, size_t vec_size){
    
    auto start = utils::mark_time();
    for (size_t i = 0; i &lt; vec_size; i++){
        vec_in_out[i] = i+i;
        }
    auto end = utils::mark_time();
    return {static_cast&lt;T&gt;(0), utils::calc_time_interval_ms(start, end)};
}

template &lt;int N, typename T&gt; requires (N &gt; 0)
static constexpr void unrolling_sum(T* accumulator_vec, T* vec_in, size_t offset){
    if constexpr (N &gt; 1) {unrolling_sum&lt;N-1, T&gt;(accumulator_vec, vec_in, offset);}
    accumulator_vec[N-1] += vec_in[offset + N-1];
}

template &lt;int N, typename T&gt; requires (N &gt; 0)
static constexpr void reduce_accs(T* accumulator_vec){
    if constexpr (N &gt; 1) {
        accumulator_vec[N-2] += accumulator_vec[N-1];
        reduce_accs&lt;N-1, T&gt;(accumulator_vec);
    }
}

template &lt;typename T, int N&gt; requires std::is_arithmetic_v&lt;T&gt; &amp;&amp; (N&gt;=1)
utils::_return_data&lt;T&gt; reduce_block(T* vec_in, size_t vec_size){    
    T accumulators[N];
    for (size_t i = 0; i&lt;N; i++){
        accumulators[i] = static_cast&lt;T&gt;(0);
    }
    auto start = utils::mark_time();
    size_t i = 0;
    for (;i+N-1 &lt; vec_size; i+=N){
        unrolling_sum&lt;N, T&gt;(accumulators, vec_in, i);
    }
    for (;i &lt; vec_size; i++){
        accumulators[0] += vec_in[i];
    }
    reduce_accs&lt;N, T&gt;(accumulators);
    auto end = utils::mark_time();
    return {accumulators[0], utils::calc_time_interval_ms(start, end)};
}

typedef return_data (*target_func_ptr)(float*, size_t);

std::unordered_map&lt;std::string, PRINT_MODE&gt; print_flags = {
    {"-printCSV", CSV},
    {"-printVec", VECTOR}
};

std::unordered_map&lt;std::string, target_func_ptr&gt; modes = {
    {"SINGLE", reduce_block&lt;float,1&gt;},
    {"BLOCK2",  reduce_block&lt;float, 2&gt;},
    {"BLOCK4",  reduce_block&lt;float, 4&gt;},
    {"BLOCK8",  reduce_block&lt;float, 8&gt;},
    {"BLOCK16", reduce_block&lt;float, 16&gt;},
};

int main(int argc, char* argv[]){
    PRINT_MODE print_mode = REGULAR;
    if (argc &lt; 3){
        printf("Insufficient arguments, use: %s &lt;MODE&gt; &lt;VEC_SIZE&gt; [-printCSV | -printVec]\n", argv[0]);
        printf("&lt;MODE&gt; being either SINGLE or BLOCK&lt;2 | 4 | 8 | 16&gt;\n");
        exit(1);
    } else{
        if (argc &gt; 4) {
            printf("Too many arguments starting at %s. Use: %s &lt;MODE&gt; &lt;VEC_SIZE&gt; [-printCSV | -printVec]\n",
                argv[4], argv[0]);
            exit(1);
        }
        if (argc == 4){
            auto temp_print = print_flags.find(argv[3]);
            if (temp_print == print_flags.end()){
                printf("Invalid argument: %s. Usage: %s &lt;MODE&gt; &lt;VEC_SIZE&gt; [-printCSV | -printVec]\n",
                    argv[3], argv[0]);
                exit(1);
            }
            print_mode = temp_print-&gt;second;
        }
    }

    auto mode = modes.find(argv[1]);
    if (mode == modes.end()){
        printf("Invalid mode: %s. Choose between SINGLE or BLOCK&lt;2 | 4 | 8 | 16&gt;\n", argv[1]);
        exit(1);
    }

    target_func_ptr func = mode-&gt;second;

    size_t params[1];
    for (auto i = 0; i &lt; 1; i++){
        params[i] = std::strtoul(argv[2+i], NULL, 10);
        if (params[i] == 0 || errno == ERANGE){
            printf("Invalid parameter: %s.\n", argv[2+i]);
            exit(1);
        }
    }

    float* vec_in = (float*) checking_malloc(params[0]*sizeof(float));

    return_data init_data = init_vec(vec_in, params[0]);
    return_data exec_data = func(vec_in, params[0]);

    switch (print_mode)
    {
    case VECTOR:
        print_vec(vec_in, params[0]);
        break;
    case CSV:
        printf("%s,%lu,%f\n", "VEC_INIT", params[0], init_data.time_ms);
        printf("%s,%lu,%f\n", argv[1], params[0], exec_data.time_ms);
        break;
    default:
        printf("Result value: %f; in %f ms\n", exec_data.res, exec_data.time_ms);
        break;
    }

    free(vec_in);
    return 0;
}</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title">run_tests.sh</summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">EXEC_FILE="./a.out"
PYTHON_EXEC=python3
MODES="SINGLE BLOCK2 BLOCK4 BLOCK8 BLOCK16"
INPUT_SIZE=10
MAX_SIZE=100000000 #10^8
NUM_SAMPLES=5
STEP=5
GROWTH_FACTOR=0.5
OUTPUT_FILE=$1
STATUS=0

if [ -z "$OUTPUT_FILE" ]
then
    echo "Pass the path to an output file, use: $0 &lt;path/to/output&gt;"
    exit
fi
echo MODE,VEC_SIZE,TIME_MS &gt; $OUTPUT_FILE

while [ "$INPUT_SIZE" -lt "$MAX_SIZE" ]
do
    for MODE in $MODES
    do
        SAMPLE=1
        while [ "$SAMPLE" -le "$NUM_SAMPLES" ]
        do
            echo running "$EXEC_FILE $MODE $INPUT_SIZE -printCSV"
            $EXEC_FILE $MODE $INPUT_SIZE -printCSV &gt;&gt; $OUTPUT_FILE
            STATUS=$?
            if [ "$STATUS" -ne 0 ]
            then
                #intended for when the MAT_SIDE is too big for the program to allocate this much memory
                echo Some error occurred, stopping early.
                exit
            fi
            SAMPLE=$(($SAMPLE+1))
        done
    done
    INPUT_SIZE=$(($INPUT_SIZE+$STEP))
    STEP=$($PYTHON_EXEC -c "import math; print(int(max((10**math.log10($INPUT_SIZE)//10)*$GROWTH_FACTOR, $STEP)))")
done</code></pre>
</div>
</div>
</div>
</details>
<details>
<summary class="title">process_data.py</summary>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import pandas as pd
import matplotlib.pyplot as plt
import sys

if len(sys.argv) &lt; 4: print(f"Too few arguments, use {sys.argv[0]} &lt;input_filepath&gt; &lt;img_output_filepath&gt; &lt;csv_output_filepath&gt;")
if len(sys.argv) &gt; 4: print(f"Too many arguments, use {sys.argv[0]} &lt;input_filepath&gt; &lt;img_output_filepath&gt; &lt;csv_output_filepath&gt;")

data = pd.read_csv(sys.argv[1])

data = data.groupby(['MODE', 'VEC_SIZE']).mean().reset_index()

size = (16,9)
param_cutoff = 10**9
fig, ax = plt.subplots(figsize=size)

cutoff = data[data['VEC_SIZE'] &lt; param_cutoff]

for label in pd.unique(data['MODE']):
    filtered = cutoff[cutoff['MODE']==label]
    x = filtered['VEC_SIZE']
    y = filtered['TIME_MS']
    ax.plot(x, y, label=label, marker='o')

ax.set_xlabel('VEC_SIZE')
ax.set_ylabel('mean time (ms)')
ax.set_title("5 samples per VEC_SIZE, ran on a AMD Ryzen 5 7600, compiled with -O0")
fig.suptitle("Time comparison between algorithms")

linear = True
#linear = False
if linear:
    ax.set_xlim(left=cutoff['VEC_SIZE'].min(), right=cutoff['VEC_SIZE'].max())
    ax.set_ylim(bottom=data['TIME_MS'].min())
else:
    ax.set_xscale('log')
    ax.set_yscale('log')
ax.legend()
plt.tight_layout()
fig.savefig(sys.argv[2])
data.to_csv(sys.argv[3])</code></pre>
</div>
</div>
</div>
</details>
</div>
</div>
</div>
<div class="paragraph nav-footer">
<p>← Previous: <a href="gargalo-de-von-neumann.html">Gargalo de Von Neumann e a Cache</a> | ↑ Up: <a href="index.html">Programação Paralela</a> | Next: <a href="fontes-de-demanda-por-performance-precisao.html">Fontes de demanda por performance: precisão</a> →</p>
</div>
</div>
<div id="footer" style="max-width: 80%;">
<div id="footer-text">
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>